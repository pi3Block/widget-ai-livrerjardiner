"""
Constantes pour le module LLM.
"""

# Statuts de requête
REQUEST_STATUS_PENDING = "PENDING"
REQUEST_STATUS_PROCESSING = "PROCESSING"
REQUEST_STATUS_COMPLETED = "COMPLETED"
REQUEST_STATUS_FAILED = "FAILED"
REQUEST_STATUS_TIMEOUT = "TIMEOUT"

# Modèles disponibles
MODEL_GPT_3_5_TURBO = "gpt-3.5-turbo"
MODEL_GPT_4 = "gpt-4"
MODEL_GPT_4_TURBO = "gpt-4-turbo"

# Types de requête
REQUEST_TYPE_CHAT = "CHAT"
REQUEST_TYPE_COMPLETION = "COMPLETION"
REQUEST_TYPE_EMBEDDING = "EMBEDDING"

# Messages d'erreur
ERROR_REQUEST_NOT_FOUND = "Requête LLM non trouvée"
ERROR_INVALID_MODEL = "Modèle LLM invalide"
ERROR_API_FAILED = "Échec de l'appel à l'API LLM"
ERROR_RATE_LIMIT_EXCEEDED = "Limite de taux dépassée"
ERROR_INVALID_PROMPT = "Prompt invalide"

# Limites
MAX_PROMPT_LENGTH = 4000
MAX_RESPONSE_LENGTH = 2000
MAX_CONCURRENT_REQUESTS = 10 